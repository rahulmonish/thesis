{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config\n",
    "from transformers import Trainer, TrainingArguments, AdamW\n",
    "import torch\n",
    "import os\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPT2Config()\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.n_embd = 256\n",
    "config.n_head = 4\n",
    "config.n_layer = 4\n",
    "config.n_positions = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model: 16058112\n"
     ]
    }
   ],
   "source": [
    "num_params = model.num_parameters()\n",
    "print(f\"Number of parameters in the model: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens:  338025\n",
      "Loaded 202815 tokens for train set\n",
      "total tokens:  338025\n",
      "Loaded 67605 tokens for val set\n",
      "total tokens:  338025\n",
      "Loaded 67605 tokens for test set\n",
      "Training batch: torch.Size([32, 32]) torch.Size([32, 32])\n",
      "Validation batch: torch.Size([32, 32]) torch.Size([32, 32])\n",
      "Test batch: torch.Size([32, 32]) torch.Size([32, 32])\n"
     ]
    }
   ],
   "source": [
    "class DataLoaderLite:\n",
    "  def __init__(self, B, T, process_rank, num_processes, train_ratio=0.6, valid_ratio=0.2, mode='train'):\n",
    "      self.B = B\n",
    "      self.T = T\n",
    "      self.process_rank = 0\n",
    "      self.num_processes = 1\n",
    "      self.train_ratio = train_ratio\n",
    "      self.valid_ratio = valid_ratio\n",
    "      self.mode = mode\n",
    "\n",
    "      with open('input.txt', 'r') as f:\n",
    "          text = f.read()\n",
    "      enc = tokenizer\n",
    "      tokens = enc.encode(text)\n",
    "      self.tokens = torch.tensor(tokens)\n",
    "\n",
    "      total_length = len(self.tokens)\n",
    "      split_index_train = int(total_length * self.train_ratio)\n",
    "      split_index_val = int(total_length * (self.train_ratio + self.valid_ratio))\n",
    "\n",
    "      print(\"total tokens: \", len(self.tokens))\n",
    "\n",
    "      if self.mode == 'train':\n",
    "          self.tokens = self.tokens[:split_index_train]\n",
    "      elif self.mode == 'val':\n",
    "          self.tokens = self.tokens[split_index_train:split_index_val]\n",
    "      else:  \n",
    "          self.tokens = self.tokens[split_index_val:]\n",
    "\n",
    "      if self.process_rank == 0:\n",
    "          print(f\"Loaded {len(self.tokens)} tokens for {self.mode} set\")\n",
    "\n",
    "      self.current_position = self.B * self.T * self.process_rank\n",
    "\n",
    "  def next_batch(self):\n",
    "      B, T = self.B, self.T\n",
    "      buf = self.tokens[self.current_position : self.current_position + B * T + 1]\n",
    "      x = (buf[:-1]).view(B, T)  \n",
    "      y = (buf[1:]).view(B, T)    \n",
    "      \n",
    "      self.current_position += B * T * self.num_processes\n",
    "      if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):\n",
    "          self.current_position = self.B * self.T * self.process_rank\n",
    "      return x, y\n",
    "\n",
    "\n",
    "B = 32  \n",
    "T = 32  \n",
    "train_ratio = 0.6  \n",
    "valid_ratio = 0.2   \n",
    "test_ratio = 0.2    \n",
    "\n",
    "train_loader = DataLoaderLite(B, T, train_ratio, valid_ratio, mode='train')\n",
    "val_loader = DataLoaderLite(B, T, train_ratio, valid_ratio, mode='val')\n",
    "test_loader = DataLoaderLite(B, T, train_ratio, valid_ratio, mode='test')\n",
    "\n",
    "x_train, y_train = train_loader.next_batch()\n",
    "print(\"Training batch:\", x_train.shape, y_train.shape)\n",
    "\n",
    "x_val, y_val = val_loader.next_batch()\n",
    "print(\"Validation batch:\", x_val.shape, y_val.shape)\n",
    "\n",
    "x_test, y_test = test_loader.next_batch()\n",
    "print(\"Test batch:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_log_dir = 'mlp/mlflow_logs/'\n",
    "os.makedirs(mlflow_log_dir, exist_ok=True)\n",
    "mlflow.set_tracking_uri(mlflow_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 0, Training Loss: 10.837706565856934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 100, Training Loss: 9.00510025024414\n",
      "Epoch 1, Validation Loss: 7.558545264330777\n",
      "Epoch 2, Step 0, Training Loss: 7.365004062652588\n",
      "Epoch 2, Step 100, Training Loss: 6.9494547843933105\n",
      "Epoch 2, Validation Loss: 6.600368246887669\n",
      "Epoch 3, Step 0, Training Loss: 6.260554790496826\n",
      "Epoch 3, Step 100, Training Loss: 6.532742023468018\n",
      "Epoch 3, Validation Loss: 6.451968019658869\n",
      "Epoch 4, Step 0, Training Loss: 6.025532245635986\n",
      "Epoch 4, Step 100, Training Loss: 6.336957931518555\n",
      "Epoch 4, Validation Loss: 6.392018455447572\n",
      "Epoch 5, Step 0, Training Loss: 5.896519660949707\n",
      "Epoch 5, Step 100, Training Loss: 6.1768317222595215\n",
      "Epoch 5, Validation Loss: 6.346493713783495\n",
      "Epoch 6, Step 0, Training Loss: 5.7864227294921875\n",
      "Epoch 6, Step 100, Training Loss: 6.041418075561523\n",
      "Epoch 6, Validation Loss: 6.327969782280199\n",
      "Epoch 7, Step 0, Training Loss: 5.697930335998535\n",
      "Epoch 7, Step 100, Training Loss: 5.917299270629883\n",
      "Epoch 7, Validation Loss: 6.320606340061534\n",
      "Epoch 8, Step 0, Training Loss: 5.6193695068359375\n",
      "Epoch 8, Step 100, Training Loss: 5.828260898590088\n",
      "Epoch 8, Validation Loss: 6.306790431340535\n",
      "Epoch 9, Step 0, Training Loss: 5.553440570831299\n",
      "Epoch 9, Step 100, Training Loss: 5.741457462310791\n",
      "Epoch 9, Validation Loss: 6.313947171875925\n",
      "Epoch 10, Step 0, Training Loss: 5.448502063751221\n",
      "Epoch 10, Step 100, Training Loss: 5.649791717529297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/24 17:17:23 WARNING mlflow.utils.requirements_utils: Found torch version (2.2.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.2.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Validation Loss: 6.33620548248291\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "num_train_epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "experiment_name = \"My_Experiment\"  \n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "mlflow.start_run()\n",
    "\n",
    "mlflow.log_param(\"learning_rate\", 5e-5)\n",
    "mlflow.log_param(\"num_train_epochs\", num_train_epochs)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_train_epochs):\n",
    "  for step in range(len(train_loader.tokens) // (B * T)):\n",
    "      batch = train_loader.next_batch()\n",
    "      input_ids = batch[0].to(device)\n",
    "      labels = batch[1].to(device)\n",
    "\n",
    "      outputs = model(input_ids, labels=labels)\n",
    "      loss = outputs.loss\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      if step % 100 == 0:\n",
    "          print(f\"Epoch {epoch + 1}, Step {step}, Training Loss: {loss.item()}\")\n",
    "          mlflow.log_metric(\"training_loss\", loss.item(), step=step + epoch * (len(train_loader.tokens) // (B * T)))\n",
    "\n",
    "  model.eval()  \n",
    "  val_loss = 0.0\n",
    "  num_val_batches = len(val_loader.tokens) // (B * T)\n",
    "\n",
    "  with torch.no_grad(): \n",
    "      for val_step in range(num_val_batches):\n",
    "          val_batch = val_loader.next_batch()\n",
    "          val_input_ids = val_batch[0].to(device)\n",
    "          val_labels = val_batch[1].to(device)\n",
    "\n",
    "          val_outputs = model(val_input_ids, labels=val_labels)\n",
    "          val_loss += val_outputs.loss.item()\n",
    "\n",
    "  val_loss /= num_val_batches\n",
    "  print(f\"Epoch {epoch + 1}, Validation Loss: {val_loss}\")\n",
    "  mlflow.log_metric(\"validation_loss\", val_loss, step=epoch)\n",
    "\n",
    "mlflow.pytorch.log_model(model, \"model\")\n",
    "mlflow.end_run()\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Perplexity: 591.0631681861266\n"
     ]
    }
   ],
   "source": [
    "def evaluate_perplexity(model, dataloader):\n",
    "  model.eval()\n",
    "  total_loss = 0.0\n",
    "  total_count = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "      for step in range(len(dataloader.tokens) // (B * T)):\n",
    "          batch = dataloader.next_batch()\n",
    "          input_ids = batch[0].to(device)\n",
    "          labels = batch[1].to(device)\n",
    "\n",
    "          outputs = model(input_ids, labels=labels)\n",
    "          loss = outputs.loss\n",
    "          total_loss += loss.item() * input_ids.size(0)\n",
    "          total_count += input_ids.size(0)\n",
    "\n",
    "  avg_loss = total_loss / total_count\n",
    "  perplexity = math.exp(avg_loss)\n",
    "  return perplexity\n",
    "\n",
    "test_perplexity = evaluate_perplexity(model, test_loader)\n",
    "print(f'Test Perplexity: {test_perplexity}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
